{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ec5f956",
   "metadata": {},
   "source": [
    "# take the following code to run the Google Colab server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b85177",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pyngrok nest_asyncio fastapi uvicorn\n",
    "\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "port = 7860\n",
    "\n",
    "ngrok.kill()\n",
    "ngrok.set_auth_token(\"Your Private Key from NGROK\")\n",
    "\n",
    "public_url = ngrok.connect(port, bind_tls=True)\n",
    "print(f\"ğŸ”— Public FastAPI URL: {public_url}/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84748980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Form, UploadFile, File\n",
    "from pydantic import BaseModel\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "import uuid, os, torch, traceback, asyncio\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from typing import Optional\n",
    "import base64\n",
    "from io import BytesIO\n",
    "# ========== setting FastAPI ==========\n",
    "app = FastAPI()\n",
    "\n",
    "OUTPUT_DIR = \"stable_diffusion_output\"\n",
    "EDITED_DIR = \"edited_images\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(EDITED_DIR, exist_ok=True)\n",
    "\n",
    "app.mount(\"/generated\", StaticFiles(directory=OUTPUT_DIR), name=\"generated\")\n",
    "app.mount(\"/edited\", StaticFiles(directory=EDITED_DIR), name=\"edited\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ========== Load Models ==========\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device)\n",
    "pipe2 = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "# ========== Concurrency Control ==========\n",
    "pipe_semaphore = asyncio.Semaphore(2)  # allow 2 concurrent generations\n",
    "\n",
    "# ========== Prompt structure ==========\n",
    "class Prompt(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class EditImageRequest(BaseModel):\n",
    "    prompt: str\n",
    "    image_base64: str  \n",
    "\n",
    "\n",
    "# ========== Generate one image (single) ==========\n",
    "@app.post(\"/generate_image\")\n",
    "async def generate_image_endpoint(prompt: Prompt):\n",
    "    try:\n",
    "        async with pipe_semaphore:\n",
    "            pipe.scheduler.set_timesteps(50)\n",
    "            result = pipe(prompt.text, num_inference_steps=50)\n",
    "            image = result.images[0]\n",
    "\n",
    "        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Bytes\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        img_bytes = buffered.getvalue()\n",
    "\n",
    "        # ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Base64\n",
    "        img_base64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "        return {\"image_base6\": img_base64}\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "# ========== Core async image generation ==========\n",
    "async def generate_image_async(prompt_text: str) -> str:\n",
    "    async with pipe_semaphore:\n",
    "        try:\n",
    "            pipe.scheduler.set_timesteps(50)\n",
    "            result = pipe(prompt_text, num_inference_steps=50)\n",
    "            if result.images:\n",
    "                image = result.images[0]\n",
    "                filename = f\"{uuid.uuid4().hex}.png\"\n",
    "                file_path = os.path.join(OUTPUT_DIR, filename)\n",
    "                image.save(file_path)\n",
    "                return f\"generated/{filename}\"\n",
    "            else:\n",
    "                return \"error: no image generated\"\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return \"error: exception\"\n",
    "\n",
    "# ========== Generate multiple images in parallel ==========\n",
    "@app.post(\"/multi_image_generation\")\n",
    "async def multi_image_generation(prompt: Prompt, count: int = 3):\n",
    "    try:\n",
    "        if not prompt.text.strip():\n",
    "            return JSONResponse(content={\"error\": \"Prompt is required.\"}, status_code=400)\n",
    "\n",
    "        # Launch tasks immediately and let them run independently\n",
    "        tasks = [asyncio.create_task(generate_image_async(prompt.text)) for _ in range(count)]\n",
    "        urls = []\n",
    "\n",
    "        for task in tasks:\n",
    "            result = await task\n",
    "            urls.append(result)\n",
    "\n",
    "        return {\"urls\": urls}\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "# ========== Image Editing using img2img ==========\n",
    "@app.post(\"/edit_image\")\n",
    "async def edit_image(request: EditImageRequest):\n",
    "    try:\n",
    "        # ÙÙƒ ØªØ´ÙÙŠØ± ØµÙˆØ±Ø© base64\n",
    "        image_data = base64.b64decode(request.image_base64)\n",
    "        img = Image.open(BytesIO(image_data)).convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Stable Diffusion\n",
    "        async with pipe_semaphore:\n",
    "            pipe2.scheduler.set_timesteps(50)\n",
    "            result = pipe2(\n",
    "                prompt=request.prompt,\n",
    "                image=img,\n",
    "                strength=0.75,\n",
    "                guidance_scale=7.5,\n",
    "                num_inference_steps=50,\n",
    "            )\n",
    "\n",
    "        edited_image = result.images[0]\n",
    "\n",
    "        # Ø­ÙØ¸ Ø¥Ù„Ù‰ BytesIO Ø«Ù… ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ base64\n",
    "        buffered = BytesIO()\n",
    "        edited_image.save(buffered, format=\"PNG\")\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        return {\"image_base64\": img_base64}\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "@app.post(\"/is_available\")\n",
    "async def check():\n",
    "  return {\"ready\": True}\n",
    "\n",
    "# ========== Run FastAPI Server ==========\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=7860)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irym_0.0.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
