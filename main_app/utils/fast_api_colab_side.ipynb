{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ec5f956",
   "metadata": {},
   "source": [
    "# Take the following code to and run it on Google Colab use GPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b85177",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pyngrok nest_asyncio fastapi uvicorn\n",
    "\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "port = 7860\n",
    "\n",
    "ngrok.kill()\n",
    "ngrok.set_auth_token(\"Your Private Key from NGROK\")\n",
    "\n",
    "public_url = ngrok.connect(port, bind_tls=True)\n",
    "print(f\"🔗 Public FastAPI URL: {public_url}/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84748980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Form, UploadFile, File\n",
    "from pydantic import BaseModel\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "import uuid, os, torch, traceback, asyncio\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from typing import Optional\n",
    "import base64\n",
    "from io import BytesIO\n",
    "# ========== setting FastAPI ==========\n",
    "app = FastAPI()\n",
    "\n",
    "OUTPUT_DIR = \"stable_diffusion_output\"\n",
    "EDITED_DIR = \"edited_images\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(EDITED_DIR, exist_ok=True)\n",
    "\n",
    "app.mount(\"/generated\", StaticFiles(directory=OUTPUT_DIR), name=\"generated\")\n",
    "app.mount(\"/edited\", StaticFiles(directory=EDITED_DIR), name=\"edited\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ========== Load Models ==========\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device)\n",
    "pipe2 = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "# ========== Concurrency Control ==========\n",
    "pipe_semaphore = asyncio.Semaphore(2)  # allow 2 concurrent generations\n",
    "\n",
    "# تحسين إضافي: استخدام xformers إن توفر\n",
    "try:\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe2.enable_xformers_memory_efficient_attention()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ========== تحديد التزامن ==========\n",
    "pipe_semaphore = asyncio.Semaphore(2)  # يمكن تعديل العدد حسب موارد الجهاز\n",
    "\n",
    "# ========== الهياكل ==========\n",
    "class Prompt(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class EditImageRequest(BaseModel):\n",
    "    prompt: str\n",
    "    image_base64: str\n",
    "\n",
    "# ========== توليد صورة واحدة (للاختبار) ==========\n",
    "@app.post(\"/generate_image\")\n",
    "async def generate_image_endpoint(prompt: Prompt):\n",
    "    try:\n",
    "        async with pipe_semaphore:\n",
    "            pipe.scheduler.set_timesteps(30)\n",
    "            result = pipe(prompt.text, num_inference_steps=30)\n",
    "            image = result.images[0]\n",
    "\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        img_bytes = buffered.getvalue()\n",
    "        img_base64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "        return {\"image_base64\": img_base64}\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "# ========== توليد عدة صور دفعة واحدة ==========\n",
    "async def generate_image_batch_async(prompt_text: str, count: int = 4) -> list:\n",
    "    async with pipe_semaphore:\n",
    "        try:\n",
    "            pipe.scheduler.set_timesteps(30)\n",
    "            result = pipe(prompt_text, num_inference_steps=30, num_images_per_prompt=count)\n",
    "\n",
    "            urls = []\n",
    "            for image in result.images:\n",
    "                filename = f\"{uuid.uuid4().hex}.png\"\n",
    "                file_path = os.path.join(OUTPUT_DIR, filename)\n",
    "                image.save(file_path)\n",
    "                urls.append(f\"generated/{filename}\")\n",
    "\n",
    "            return urls\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return [\"error: exception\"]\n",
    "\n",
    "@app.post(\"/multi_image_generation\")\n",
    "async def multi_image_generation(prompt: Prompt, count: int = 4):\n",
    "    try:\n",
    "        if not prompt.text.strip():\n",
    "            return JSONResponse(content={\"error\": \"Prompt is required.\"}, status_code=400)\n",
    "\n",
    "        urls = await generate_image_batch_async(prompt.text, count)\n",
    "        return {\"urls\": urls}\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "# ========== تعديل صورة باستخدام img2img ==========\n",
    "@app.post(\"/edit_image\")\n",
    "async def edit_image(request: EditImageRequest):\n",
    "    try:\n",
    "        image_data = base64.b64decode(request.image_base64)\n",
    "        img = Image.open(BytesIO(image_data)).convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "        async with pipe_semaphore:\n",
    "            pipe2.scheduler.set_timesteps(50)\n",
    "            result = pipe2(\n",
    "                prompt=request.prompt,\n",
    "                image=img,\n",
    "                strength=0.75,\n",
    "                guidance_scale=7.5,\n",
    "                num_inference_steps=50,\n",
    "            )\n",
    "\n",
    "        edited_image = result.images[0]\n",
    "\n",
    "        buffered = BytesIO()\n",
    "        edited_image.save(buffered, format=\"PNG\")\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        return {\"image_base64\": img_base64}\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "@app.post(\"/is_available\")\n",
    "async def check():\n",
    "    return {\"ready\": True}\n",
    "\n",
    "# ========== تشغيل الخادم ==========\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=7860)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irym_0.0.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
